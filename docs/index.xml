<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>RuglioBoi</title>
<link>https://ruglio.github.io/Web/</link>
<atom:link href="https://ruglio.github.io/Web/index.xml" rel="self" type="application/rss+xml"/>
<description>A great sample blog</description>
<generator>quarto-1.5.47</generator>
<lastBuildDate>Mon, 24 Jun 2024 22:00:00 GMT</lastBuildDate>
<item>
  <title>Introduction to Gaussian Processes</title>
  <dc:creator>Andrea Ruglioni</dc:creator>
  <link>https://ruglio.github.io/Web/posts/gaussian_processes/gp.html</link>
  <description><![CDATA[ 





<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>This article introduces Gaussian Processes (GPs), discussing their mathematical foundations and practical applications in regression tasks. Python code examples demonstrate their implementation with squared exponential and Matérn kernels, including handling noisy measurements.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Gaussian Processes (GPs) are a powerful, non-parametric tool for modeling and understanding data. They provide a probabilistic approach to learning in kernel-defined function spaces, making them particularly useful for regression and optimization tasks.</p>
</section>
<section id="gaussian-processes" class="level2">
<h2 class="anchored" data-anchor-id="gaussian-processes">Gaussian Processes</h2>
<section id="what-is-a-gaussian-process" class="level3">
<h3 class="anchored" data-anchor-id="what-is-a-gaussian-process">What is a Gaussian Process?</h3>
<p>Gaussian Processes (GPs) are a non-parametric method for regression and classification tasks. They define a distribution over functions and can provide uncertainty measures for predictions.</p>
</section>
<section id="mathematical-formulation" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-formulation">Mathematical Formulation</h3>
<p>A Gaussian Process is completely specified by its mean function <img src="https://latex.codecogs.com/png.latex?m(x)"> and covariance function <img src="https://latex.codecogs.com/png.latex?k(x,%20x')">:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x)%20%5Csim%20GP(m(x),%20k(x,%20x'))%0A"></p>
<p>where:</p>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?m(x)%20=%20%5Cmathbb%7BE%7D%5Bf(x)%5D"></li>
<li><img src="https://latex.codecogs.com/png.latex?k(x,%20x')%20=%20%5Cmathbb%7BE%7D%5B(f(x)%20-%20m(x))(f(x')%20-%20m(x'))%5D"></li>
</ul>
<p>The mean function is often assumed to be zero for simplicity <img src="https://latex.codecogs.com/png.latex?m(x)%20=%200">.</p>
<p>The covariance function (kernel) defines the shape and smoothness of the functions sampled from the GP. Common choices for kernels include the squared exponential (RBF) kernel and the Matérn kernel.</p>
</section>
<section id="squared-exponential-kernel" class="level3">
<h3 class="anchored" data-anchor-id="squared-exponential-kernel">Squared Exponential Kernel</h3>
<p>The squared exponential kernel (also known as the RBF kernel) is defined as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ak_%7B%5Ctext%7BExp%7D%7D(x,%20x')%20=%20%5Csigma%5E2%20%5Cexp%20%5Cleft(%20-%5Cfrac%7B(x%20-%20x')%5E2%7D%7B2l%5E2%7D%20%5Cright)%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"> is the variance and <img src="https://latex.codecogs.com/png.latex?l"> is the length scale.</p>
<pre class="shinylive-python" data-engine="python"><code>#| standalone: true
#| viewerHeight: 475

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal
from shiny import App, render, ui


# Define the kernel function
def exponential_quadratic_kernel(x1, x2, l=1.0, sigma2=1.0):
    """Computes the exponential quadratic kernel (squared exponential kernel)."""
    sqdist = np.sum(x1**2, 1).reshape(-1, 1) + np.sum(x2**2, 1) - 2 * np.dot(x1, x2.T)
    return sigma2 * np.exp(-0.5 / l**2 * sqdist)

# Define the input space
X = np.linspace(-4, 4, 100).reshape(-1, 1)

def plot_kernel_and_samples(l, sigma2):
    # Compute the kernel matrix
    K = exponential_quadratic_kernel(X, X, l=l, sigma2=sigma2)

    # Create the plot
    fig, ax = plt.subplots(2, 1, figsize=(18, 6), sharex=True)

    # Plot the kernel
    ax[0].plot(X, exponential_quadratic_kernel(X, np.zeros((1,1)), l=l, sigma2=sigma2))
    ax[0].set_title(f"Squared exponential kernel function")

    # Sample 5 functions from the Gaussian process defined by the kernel
    mean = np.zeros(100)
    cov = K
    samples = multivariate_normal.rvs(mean, cov, 5)

    # Plot the samples
    for i in range(5):
        ax[1].plot(X, samples[i])
    ax[1].set_title("Samples from the GP")
    ax[1].set_xlabel("x")

    plt.tight_layout()
    return fig

app_ui = ui.page_fluid(
    ui.layout_sidebar(
        ui.panel_sidebar(
            ui.input_slider("length_scale", "Length Scale (l):", min=0.1, max=5.0, value=1.0, step=0.1),
            ui.input_slider("variance", "Variance (σ²):", min=0.1, max=5.0, value=1.0, step=0.1)
        ),
        ui.panel_main(
            ui.output_plot("kernelPlot")
        )
    )
)

def server(input, output, session):
    @output
    @render.plot
    def kernelPlot():
        l = input.length_scale()
        sigma2 = input.variance()
        fig = plot_kernel_and_samples(l, sigma2)
        return fig

app = App(app_ui, server)</code></pre>
</section>
<section id="matérn-kernel" class="level3">
<h3 class="anchored" data-anchor-id="matérn-kernel">Matérn kernel</h3>
<p>The Matérn kernel is defined as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ak_%7B%5Ctext%7BMat%C3%A9rn%7D%7D(x,%20x')%20=%20%5Csigma%5E2%20%5Cfrac%7B2%5E%7B1-%5Cnu%7D%7D%7B%5CGamma(%5Cnu)%7D%20%5Cleft(%20%5Csqrt%7B2%5Cnu%7D%20%5Cfrac%7B%7Cx%20-%20x'%7C%7D%7Bl%7D%20%5Cright)%5E%7B%5Cnu%7D%20K_%7B%5Cnu%7D%20%5Cleft(%20%5Csqrt%7B2%5Cnu%7D%20%5Cfrac%7B%7Cx%20-%20x'%7C%7D%7Bl%7D%20%5Cright)%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cnu"> controls the smoothness of the function, <img src="https://latex.codecogs.com/png.latex?l"> is the length scale, <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2"> is the variance, and <img src="https://latex.codecogs.com/png.latex?K_%7B%5Cnu%7D"> is the modified Bessel function.</p>
<pre class="shinylive-python" data-engine="python"><code>#| standalone: true
#| viewerHeight: 475

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal
from shiny import App, render, ui
from scipy.special import kv, gamma
from scipy.spatial.distance import cdist


# Define the kernel function
def matern_kernel(x1, x2, l=1.0, sigma2=1.0, nu=1.5):
    """Computes the Matérn kernel."""
    D = cdist(x1, x2, 'euclidean')
    const = (2**(1-nu))/gamma(nu)
    K = const * (np.sqrt(2*nu)*D/l)**nu * kv(nu, np.sqrt(2*nu)*D/l)
    # Replace NaN values with 1 for x == x'
    K[np.isnan(K)] = 1
    K *= sigma2
    return K

# Define the input space
X = np.linspace(-4, 4, 100).reshape(-1, 1)

def plot_kernel_and_samples(l, sigma2, nu):
    # Compute the kernel matrix
    K = matern_kernel(X, X, l=l, sigma2=sigma2, nu=nu)

    # Create the plot
    fig, ax = plt.subplots(2, 1, figsize=(18, 6), sharex=True)

    # Plot the kernel
    ax[0].plot(X, matern_kernel(X, np.zeros(()), l=l, sigma2=sigma2, nu=nu))
    ax[0].set_title(f"Matern kernel function")

    # Sample 5 functions from the Gaussian process defined by the kernel
    mean = np.zeros(100)
    cov = K
    samples = multivariate_normal.rvs(mean, cov, 5)

    # Plot the samples
    for i in range(5):
        ax[1].plot(X, samples[i])
    ax[1].set_title("Samples from the GP")
    ax[1].set_xlabel("x")

    plt.tight_layout()
    return fig

app_ui = ui.page_fluid(
    ui.layout_sidebar(
        ui.panel_sidebar(
            ui.input_slider("length_scale", "Length Scale (l):", min=0.1, max=5.0, value=1.0, step=0.1),
            ui.input_slider("variance", "Variance (σ²):", min=0.1, max=5.0, value=1.0, step=0.1),
            ui.input_slider("smoothness_param", "Smoothness param (v):", min=1.5, max=5.0, value=1.5, step=0.5)
        ),
        ui.panel_main(
            ui.output_plot("kernelPlot")
        )
    )
)

def server(input, output, session):
    @output
    @render.plot
    def kernelPlot():
        l = input.length_scale()
        sigma2 = input.variance()
        nu = input.smoothness_param()
        fig = plot_kernel_and_samples(l, sigma2, nu)
        return fig

app = App(app_ui, server)</code></pre>
</section>
<section id="noisy-measurements" class="level3">
<h3 class="anchored" data-anchor-id="noisy-measurements">Noisy measurements</h3>
<p>Handling noisy observations in GPs involves adding a noise term to the covariance matrix. The noisy observations are modeled as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ay%20=%20f(x)%20+%20%5Cepsilon%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cepsilon%20%5Csim%20%5Cmathcal%7BN%7D(0,%20%5Csigma_n%5E2)">.</p>
<pre class="shinylive-python" data-engine="python"><code>#| standalone: true
#| viewerHeight: 475

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal
from shiny import App, render, ui
from scipy.spatial.distance import cdist
from scipy.special import kv, gamma

# Define the kernel functions
def exponential_quadratic_kernel(x1, x2, l=1.0, sigma2=1.0):
    """Computes the exponential quadratic kernel (squared exponential kernel)."""
    sqdist = np.sum(x1**2, 1).reshape(-1, 1) + np.sum(x2**2, 1) - 2 * np.dot(x1, x2.T)
    return sigma2 * np.exp(-0.5 / l**2 * sqdist)

def matern_kernel(x1, x2, l=1.0, sigma2=1.0, nu=1.5):
    """Computes the Matérn kernel."""
    D = cdist(x1, x2, 'euclidean')
    const = (2**(1-nu))/gamma(nu)
    K = sigma2 * const * (np.sqrt(2*nu)*D/l)**nu * kv(nu, np.sqrt(2*nu)*D/l)
    # Replace NaN values with 1 for x == x'
    K[np.isnan(K)] = 1
    return K

# Define the input space
X = np.linspace(-4, 4, 100).reshape(-1, 1)

def plot_kernels_and_samples(noise_level):
    # Generate training data with noise
    X_train = np.array([-3, -2, -1, 1, 3.5]).reshape(-1, 1)
    y_train = np.sin(X_train) + noise_level * np.random.randn(X_train.shape[0], 1).reshape(-1,1)

    # Compute the kernel matrices for training data
    K_train_exp = exponential_quadratic_kernel(X_train, X_train) + noise_level**2 * np.eye(len(X_train))
    K_s_exp = exponential_quadratic_kernel(X_train, X)
    K_ss_exp = exponential_quadratic_kernel(X, X)
    
    K_train_matern = matern_kernel(X_train, X_train) + noise_level**2 * np.eye(len(X_train))
    K_s_matern = matern_kernel(X_train, X)
    K_ss_matern = matern_kernel(X, X)

    # Compute the mean and covariance of the posterior distribution for exponential kernel
    K_train_inv_exp = np.linalg.inv(K_train_exp)
    mu_s_exp = (K_s_exp.T.dot(K_train_inv_exp).dot(y_train)).reshape(-1)
    cov_s_exp = K_ss_exp - K_s_exp.T.dot(K_train_inv_exp).dot(K_s_exp)

    # Compute the mean and covariance of the posterior distribution for Matérn kernel
    K_train_inv_matern = np.linalg.inv(K_train_matern)
    mu_s_matern = (K_s_matern.T.dot(K_train_inv_matern).dot(y_train)).reshape(-1)
    cov_s_matern = K_ss_matern - K_s_matern.T.dot(K_train_inv_matern).dot(K_s_matern)

    # Sample 5 functions from the posterior distribution for both kernels
    samples_exp = multivariate_normal.rvs(mu_s_exp, cov_s_exp, 5)
    samples_matern = multivariate_normal.rvs(mu_s_matern, cov_s_matern, 5)

    # Create the plot
    fig, ax = plt.subplots(2, 1, figsize=(18, 6), sharex=True)

    # Plot the training data and GP predictions for exponential kernel
    ax[0].scatter(X_train, y_train, color='black', zorder=10, label='Noisy observations')
    ax[0].plot(X, mu_s_exp, color='blue', label='Mean')
    ax[0].plot(X, np.sin(X), color='black', label='True function')
    ax[0].fill_between(X.ravel(), mu_s_exp - 1.96 * np.sqrt(np.diag(cov_s_exp)), mu_s_exp + 1.96 * np.sqrt(np.diag(cov_s_exp)), color="blue", alpha=0.2, label='95% confidence interval')
    # for i in range(5):
    #     ax[0].plot(X, samples_exp[i], alpha=0.5, linestyle='--')
    ax[0].set_title(f"Squared exponential kernel")
    # ax[0].legend()

    # Plot the training data and GP predictions for Matérn kernel
    ax[1].scatter(X_train, y_train, color='black', zorder=10, label='Noisy observations')
    ax[1].plot(X, mu_s_matern, color="blue", label='Mean')
    ax[1].plot(X, np.sin(X), color="black", label='True function')
    ax[1].fill_between(X.ravel(), mu_s_matern - 1.96 * np.sqrt(np.diag(cov_s_matern)), mu_s_matern + 1.96 * np.sqrt(np.diag(cov_s_matern)), color="blue", alpha=0.2, label='95% confidence interval')
    # for i in range(5):
    #     ax[1].plot(X, samples_matern[i], alpha=0.5, linestyle='--')
    ax[1].set_title(f"Matérn kernel")
    # ax[1].legend()
    ax[1].set_xlabel("x")

    plt.tight_layout()
    return fig

app_ui = ui.page_fluid(
    ui.layout_sidebar(
        ui.panel_sidebar(
            ui.input_slider("noise_level", "Noise Level (σ²ₙ):", min=0.01, max=1.0, value=0.1, step=0.01)
        ),
        ui.panel_main(
            ui.output_plot("kernelPlot")
        )
    )
)

def server(input, output, session):
    @output
    @render.plot
    def kernelPlot():
        noise_level = input.noise_level()
        fig = plot_kernels_and_samples(noise_level)
        return fig

app = App(app_ui, server)</code></pre>
<p>According to the data, the GP model effectively captures the underlying function and provides uncertainty estimates.</p>


</section>
</section>

 ]]></description>
  <guid>https://ruglio.github.io/Web/posts/gaussian_processes/gp.html</guid>
  <pubDate>Mon, 24 Jun 2024 22:00:00 GMT</pubDate>
</item>
<item>
  <title>Post With Code</title>
  <dc:creator>Harlow Malloc</dc:creator>
  <link>https://ruglio.github.io/Web/posts/post-with-code/</link>
  <description><![CDATA[ 





<p>This is a post with executable code.</p>
<div id="cell-fig-plot" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"></span>
<span id="cb1-4">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>np.pi)</span>
<span id="cb1-5">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sin(x)</span>
<span id="cb1-6"></span>
<span id="cb1-7">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots()</span>
<span id="cb1-8">ax.plot(x, y)</span>
<span id="cb1-9">ax.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb1-10">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-plot" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://ruglio.github.io/Web/posts/post-with-code/index_files/figure-html/fig-plot-output-1.png" width="590" height="411" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: sine plot
</figcaption>
</figure>
</div>
</div>
</div>
<p>Figure&nbsp;1 is a plot</p>



 ]]></description>
  <category>news</category>
  <category>code</category>
  <category>analysis</category>
  <guid>https://ruglio.github.io/Web/posts/post-with-code/</guid>
  <pubDate>Mon, 24 Jun 2024 22:00:00 GMT</pubDate>
  <media:content url="https://ruglio.github.io/Web/posts/post-with-code/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Welcome To My Blog</title>
  <dc:creator>Tristan O&#39;Malley</dc:creator>
  <link>https://ruglio.github.io/Web/posts/welcome/</link>
  <description><![CDATA[ 





<p>This is the first post in a Quarto blog. Welcome!</p>
<p><img src="https://ruglio.github.io/Web/posts/welcome/thumbnail.jpg" class="img-fluid"></p>
<p>Since this post doesn’t specify an explicit <code>image</code>, the first image in the post will be used in the listing page of posts.</p>



 ]]></description>
  <category>news</category>
  <guid>https://ruglio.github.io/Web/posts/welcome/</guid>
  <pubDate>Fri, 21 Jun 2024 22:00:00 GMT</pubDate>
</item>
</channel>
</rss>
